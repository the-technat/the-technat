<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>ssh technat</title><link>https://technat.ch/</link><description>Recent content on ssh technat</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://technat.ch/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://technat.ch/about/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/about/</guid><description>Hi I&amp;rsquo;m technat. Kubernetes Engineer, minimalist, perfectionist and enthusiast for everything that looks like a container.
üî≠ I‚Äôm currently working on an IoT project called weddingphone. üå± I‚Äôm always learning many things in parallel, I can&amp;rsquo;t list them all&amp;hellip; üíûÔ∏è I‚Äôm looking to collaborate on Terraform Modules, Go applications and other K8s / CNCF projects around Kubernetes üí¨ Ask me about Go, Terraform, CI/CD and Kubernetes or take a look at my Wiki üì´ You can reach me at technat@technat.</description></item><item><title>arch</title><link>https://technat.ch/linux/arch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/linux/arch/</guid><description>Install Arch Linux on my daily driver notebook.
Components in this installation Arch Linux is flexible and there are many guides out there that show you how to install it. During my research I found it unpleasant having to read the entire article before knowing what software the article shows to configure for diferent components. Therefore here&amp;rsquo;s the list of what Software I use in my Arch Linux Installation:
System Type: EFI Partitioning: LVM (ext4) on LUKS partition -&amp;gt; all data encrypted (except boot partition) Encryption: Keyfile for automatic decryption on boot Bootloader: systemd-boot initramfs: systemd-init hooks SWAP: swapfile Disclaimer I documented in this guide how I installed Arch Linux on my notebook to have a reference I can use if something goes wrong and I need to know how I configured it.</description></item><item><title>argocd</title><link>https://technat.ch/kubernetes/argocd/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/kubernetes/argocd/</guid><description>Chart: https://artifacthub.io/packages/helm/argo/argo-cd
Repo: https://argo-cd.readthedocs.io/en/stable/getting_started/#1-install-argo-c://github.com/argoproj/argo-helm
Install helm upgrade -i argocd argo/argo-cd -n argocd --create-namespace -f argocd-values.yaml Local Users Create Add the following to the argocd-cm ConfigMap:
accounts.dev: login accounts.ci: apiKey accounts.technat: login accounts.admin.enabled: &amp;#34;false&amp;#34; Or the argocd.config key in the helm chart.
Permissions Now edit the argocd-rbac-cm ConfigMap and add the following to map the technat user admin rights.
data: policy.default: role:readonly policy.csv: | g, technat, role:admin p, role:ci, applications, *, */*, allow g, ci, role:ci Or the argocd.</description></item><item><title>backups</title><link>https://technat.ch/linux/backups/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/linux/backups/</guid><description>This page describes how to backup files using restic.
Concept We need backups, that&amp;rsquo;s abvious. But how? My concept is to only backup data on a file based layer, no server backups or configuration backup as this should all be in a wiki or in a git repository.
As backup target I use Infomaniak Swiss Backup. Primarly using restic and an s3 repository.
Restic Init Repository The restic s3 repository needs to be initialized.</description></item><item><title>cert-manager</title><link>https://technat.ch/kubernetes/cert-manager/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/kubernetes/cert-manager/</guid><description>Installation helm repo add jetstack https://charts.jetstack.io helm repo update helm show values jetstack/cert-manager &amp;gt; cert-manager-values.yaml kubectl create ns cert-manager helm upgrade -i cert-manager -n cert-manager jetstack/cert-manager -f cert-manager-values.yaml Let&amp;rsquo;s Encrypt Issuer kubectl apply -f letsencrypt-staging.yaml kubectl apply -f letsencrypt-production.yaml Resources - https://cert-manager.io/docs/tutorials/acme/ingress/
Files Custom Values: cert-manager-values.yaml
Let&amp;rsquo;s Encrypt Staging Issuer: letsencrypt-staging.yaml
Let&amp;rsquo;s Encrypt Production Issuer: letsencrypt-production.yaml</description></item><item><title>cloud-init</title><link>https://technat.ch/linux/cloud_init/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/linux/cloud_init/</guid><description>You want to use cloud-init, for sure. Here are my configs I usually use for bootstraping new servers quickly.
Debian #cloud-config &amp;lt;hostname&amp;gt; package_update: true package_upgrade: true packages: - vim - git - wget - curl - dnsutils users: - name: technat groups: sudo sudo: ALL=(ALL) NOPASSWD:ALL # Allow any operations using sudo gecos: &amp;#34;Admin user created by cloud-init&amp;#34; shell: /usr/bin/bash ssh-authorized_keys: - ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIJov21J2pGxwKIhTNPHjEkDy90U8VJBMiAodc2svmnFC cardno:18 055 612 write_files: - path: /etc/ssh/sshd_config content: | Port 59245 PermitRootLogin no PermitEmptyPasswords no PasswordAuthentication no PubkeyAuthentication yes Include /etc/ssh/sshd_config.</description></item><item><title>coredns</title><link>https://technat.ch/linux/coredns/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/linux/coredns/</guid><description>Server preparations DNSUtils As it is a DNS Server we want some tools to debug:
sudo apt install dnsutils -y Service Account For the coredns Service to run we need a system user:
cat &amp;lt;&amp;lt;EOF &amp;gt;/usr/lib/sysusers.d/coredns-sysusers.conf u coredns - &amp;#34;CoreDNS is a DNS server that chains plugins&amp;#34; /var/lib/coredns EOF TMP Files And add a directory:
cat &amp;lt;&amp;lt;EOF &amp;gt;/usr/lib/tmpfiles.d/coredns-tmpfiles.conf d /var/lib/coredns 0755 coredns coredns - EOF Installation Penguins are running $CoreDNS.</description></item><item><title>cronjobs</title><link>https://technat.ch/linux/cronjobs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/linux/cronjobs/</guid><description>Cronjobs are usefull for different maintenance tasks. This page lists some tipps and tricks about them.
Scheduling cronjobs When you have seen the cron scheduling syntax */1 * * * * you know how confusing it can be to find the correct schedule. Tipp: use https://crontab.guru/ to figure out your schedule.
Send mails from cronjobs We are using postfix for this. ssmtp would be more minimal but I have tried it extensively and it didn&amp;rsquo;t work.</description></item><item><title>external-dns</title><link>https://technat.ch/kubernetes/external-dns/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/kubernetes/external-dns/</guid><description>Prepare See https://github.com/kubernetes-sigs/external-dns/tree/master/charts/external-dns
Install kubectl create ns external-dns helm upgrade -i external-dns -n external-dns external-dns/external-dns --set env.0.value=&amp;lt;APITOKEN_HERE&amp;gt; -f external-dns-values.yaml Files Custom Values: external-dns-values.yaml</description></item><item><title>fairphone</title><link>https://technat.ch/linux/fairphone/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/linux/fairphone/</guid><description>Tools needed sudo pacman -S android-tools android-udev USB Debugging See here. Don&amp;rsquo;t forget to enable the developer status before searching for advanced settings ;)
Unlock Code Did the installation manual Code: 62e23157</description></item><item><title>faultier</title><link>https://technat.ch/linux/faultier/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/linux/faultier/</guid><description>The faultier is the answer to the Chicken and the Egg. If you have desinged anything in IT, you know that there is always at least one Chicken and Egg situation where you have to choose what depends on what. This is exactly what the faultier solves. It&amp;rsquo;s a VM created by Terraform, but configured manually. Why? Because there are some services that just need to exist if you want to setup an automated environment.</description></item><item><title>gitea</title><link>https://technat.ch/linux/gitea/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/linux/gitea/</guid><description>Setup a private Git on a Debian 11 machine.
Preparation: Data Disk Gitea needs a place to store it¬¥s repositories and files. This will be under /var/lib/gitea. In order to have the data separated from the operating system a second disk /dev/sdb will be used for that. Also the database will have it¬¥s data stored a /var/lib/mysql so this should also be on the second disk.
Here is how I did it with LVM:</description></item><item><title>gitlab-runners</title><link>https://technat.ch/kubernetes/gitlab-runner/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/kubernetes/gitlab-runner/</guid><description>Chart: https://artifacthub.io/packages/helm/gitlab/gitlab-runner
Preparations helm repo add gitlab http://charts.gitlab.io/ helm show values gitlab/gitlab-runner &amp;gt; gitlab-runner-values.yaml kubectl create ns gitlab-runners Configure Cache Apply the CRD to create the cache:
kubectl apply -f cache-bucket.yaml Get the information from the configmap and fill it into the helm values:
kubectl get configmap gitlab-cache -o yaml For the credentials we have to create a new secret based on the current one that rook-ceph created:
kubectl create secret generic s3access \ --from-literal=accesskey=&amp;#34;&amp;#34; \ --from-literal=secretkey=&amp;#34;&amp;#34; Install helm upgrade -i k8s-at-hetzner-runner -n gitlab-runners gitlab/gitlab-runner -f k8s-at-hetzner-runner-values.</description></item><item><title>heimdall</title><link>https://technat.ch/kubernetes/heimdall/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/kubernetes/heimdall/</guid><description>Chart: https://artifacthub.io/packages/helm/k8s-at-home/heimdall
Installation helm repo add k8s-at-home https://k8s-at-home.com/charts/ helm repo update helm show values k8s-at-home/heimdall &amp;gt; heimdall-values.yaml helm upgrade -i heimdall --create-namespace -n heimdall k8s-at-home/heimdall -f heimdall-values.yaml Files Custom heimdall values: heimdall-values.yaml
Service for Heimdall: heimdall-lb.yaml</description></item><item><title>homelab_concept_old</title><link>https://technat.ch/linux/homelab_concept_old/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/linux/homelab_concept_old/</guid><description>Introduction This page serves as a concept for my homelab. It defines some basic principles that are important for me when homelabing. Note though that it can evolve over time and that it&amp;rsquo;s just a hobby.
To Do : Explain technat.ch and technat.home at the beginning and restructure accordingly : Think about services hosted twice, once for the cloud and once at home : Backup Concept: how to get the data from Swiss Backup to the NAS?</description></item><item><title>ingress-nginx</title><link>https://technat.ch/kubernetes/ingress-nginx/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/kubernetes/ingress-nginx/</guid><description>References - https://github.com/kubernetes/ingress-nginx
- https://kubernetes.github.io/ingress-nginx/deploy/#using-helm
Install k create ns ingress-nginx helm upgrade ingress-nginx -i -n ingress-nginx ingress-nginx/ingress-nginx -f helm-ingress-nginx.yaml External Access To have external access add port-forwarding rules in Firewall to forward 80/443 to ingress-nginx
Files Custom Values: helm-ingress-nginx.yaml</description></item><item><title>k8s_kubeadm</title><link>https://technat.ch/kubernetes/k8s_kubeadm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/kubernetes/k8s_kubeadm/</guid><description>This is my current approach on how to setup Kubernetes for labing purposes. I&amp;rsquo;m not a fan of automation when It comes to trying things out, so my setup is completely manual using kubeadm.
Here are some other aspects of my setup that will be part of this guide:
My Cloud Provider of choice is currently Hetzner Public facing K8s - no traffic going over private networks My CNI of choice is currently Cilium with pod to pod encryption using wireguard Prerequisites Before we dive into the details on how to setup, here are some prerequisites to met when you want to follow allong:</description></item><item><title>kubeinvaders</title><link>https://technat.ch/kubernetes/kubeinvaders/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/kubernetes/kubeinvaders/</guid><description>Preparations helm repo add kubeinvaders https://lucky-sideburn.github.io/helm-charts Install helm upgrade -i kubeinvaders -n kubeinvaders --create-namespace kubeinvaders/kubeinvaders -f kubeinvaders-values.yaml Files Custom Values: kubeinvaders-values.yaml</description></item><item><title>lv-extending</title><link>https://technat.ch/kubernetes/lv-extending/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/kubernetes/lv-extending/</guid><description>Containers have their temporare file system on the node under /var/.... This means that K8s worker nodes need to have a big /var if you mount this on a separate partition.
If using LVM and VMs we can manually extend the logical volume behind /var. But for this the volume must be unmounted, so we need to use a live installation.
First drain the node:
k drain node-0x --ignore-daemonsets --delete-empty-dir-data Then we shutdown the node and mount a live-iso.</description></item><item><title>metallb</title><link>https://technat.ch/kubernetes/metallb/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/kubernetes/metallb/</guid><description>Install helm upgrade -i metallb -n metallb-system -f metallb-values.yaml metallb/metallb Files Custom Values: metallb-values.yaml
Layer2 Config: metallb-config.yaml</description></item><item><title>metrics-server</title><link>https://technat.ch/kubernetes/metrics-server/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/kubernetes/metrics-server/</guid><description>See https://github.com/kubernetes-sigs/metrics-server/blob/master/charts/metrics-server/README.md
Install helm upgrade -i metrics-server metrics-server/metrics-server -f metrics-server-values.yaml Files Custom Values: metrics-server-values.yaml</description></item><item><title>minecraft_server</title><link>https://technat.ch/linux/minecraft_server/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/linux/minecraft_server/</guid><description>Einleitung Diese Anleitung zeigt wie der offiziele Minecraft Server (Java-Edition) von Mojang sowohl auf Windows als auch auf Linux installiert wird.
Vorbedingungen Die folgenden Annahmen / Rahmenbedingungen werden getroffen / angenommen f√ºr diese Anleitung:
Ein Server (Windows/Linux) wurde bereits erstellt und man kann mittels SSH/RDP darauf verbinden Der Server hat eine √∂ffentliche IP Adresse oder Port 25565 TCP/UDP wurde mittels Port-Forwarding freigeschaltet Der Server ist pingbar im Internet (ICMP traffic erlaubt) Der Server ist aktualisiert und gepatched Windows Java Der Minecraft Server ist in Java geschrieben.</description></item><item><title>nextcloud</title><link>https://technat.ch/linux/nextcloud/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/linux/nextcloud/</guid><description>My personal nextcloud on hcloud.
Infrastructure Managed by terraform, see this file.
DNS Managed by terraform, see here.
OS Preparations Shell tipps Edit the ENV_PATH variable in /etc/login.defs to contain /sbin:/usr/sbin Add the file ~/.bash_aliases with the following content: alias off=&amp;#34;sudo -u www-data php /var/www/cloud.technat.ch/occ maintenance:mode --off&amp;#34; alias on=&amp;#34;sudo -u www-data php /var/www/cloud.technat.ch/occ maintenance:mode --on&amp;#34; alias occ=&amp;#34;sudo -u www-data php /var/www/cloud.technat.ch/occ&amp;#34; alias l=&amp;#34;ls -lahF&amp;#34; External OS Disk /dev/sdb is configured as our storage disk using LVM.</description></item><item><title>nextcloud_maintenance</title><link>https://technat.ch/linux/nextcloud_maintenance/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/linux/nextcloud_maintenance/</guid><description>Backups To backup a nextcloud instance you have to save the following directories:
Webroot (usually under /var/www) Data dir (defined in nextcloud&amp;rsquo;s config) DB Dump -&amp;gt; either using mysqldump or pgdump To do a mysql dump you can use the following command:
sudo mysqldump -u root -p ncdb -R -e --triggers --single-transaction &amp;gt; ncdb.sql ncdb is the name of you database root is the user that is allowed to connect to mysql using unix socket authentication And for pgdump:</description></item><item><title>proxmox</title><link>https://technat.ch/linux/proxmox/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/linux/proxmox/</guid><description>This page shows one of many approaches how Proxmox can be installed and configured on a Dedicated Root Server from Hetzner.
Server This doc was created using an AX41-NVME server with the following specs:
CPU: AMD Ryzen 5 3600 6-Core Processor Memory: 64GB DDR4 Ram Disks: 2x 512GB NVME Data Disks: 2x 1TB SATA SSD NIC: 1 GBit/s Port
Hetzner Firewall In the Hetzner Robot you have the option to add firewall rules for your server on Hetzner&amp;rsquo;s Infrastructure.</description></item><item><title>proxmox_cloud_init</title><link>https://technat.ch/linux/proxmox_cloud_init/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/linux/proxmox_cloud_init/</guid><description>This page describes how to create a cloud-init ready vm template in proxmox
Create initial VM Key Value ID 9000 Name debian-11-generic ISO debian-11.0.0-adm64.netinst.iso Qemu-Agent 1 BIOS OVMF (UEFI) EFI Disk 1, local-zfs Machine type q35 Graphic card SPICE OS Disk local-zfs, 32gb, io-thread=1,discard=1 Cores 2 Memory 2048MB Net0 vmbr4, firewall=0 K8S Key Value ID 9008 Name debian-11-k8s ISO debian-11.0.0-adm64.netinst.iso Qemu-Agent 1 Graphic card SPICE BIOS OVMF (UEFI) EFI Disk 1, local-zfs Machine type q35 OS Disk local-zfs, 32gb, io-thread=1,discard=1 Cores 2 Memory 4096MB Net0 vmbr4, firewall=0 Initial setup Values used when installing the OS for the first time:</description></item><item><title>rook-ceph</title><link>https://technat.ch/kubernetes/rook-ceph/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/kubernetes/rook-ceph/</guid><description>Maybe you know rook.io. Rook is a storage operator.
Rook can configure Ceph clusters based on CRDS. Ceph provides Block, File and Object storage.
The workers nodes used in this values file have each an empty 50GB disk attached. By default rook will only take disks that are unused.
rook-ceph chart We start by installing the rook-operator which gives us the base to deploy ceph later on:
helm repo add rook-release https://charts.</description></item><item><title>sway-de</title><link>https://technat.ch/linux/sway-de/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/linux/sway-de/</guid><description>My Setup of a Wayland Compositor with all the tools needed to be productive, while only having what is really necessary (minimalistic approach).
Overview This guide will show from A-Z the steps done, the configs modified and tools installed to get a decent working graphical environment, just with a wayland compositor and a lot of open-source community-tools.
As for all we need some concepts and principles. Mine are:
If possible let default configuration as is and add custom config clearly visible -&amp;gt; include instead of copy and modify Don&amp;rsquo;t change keybindings!</description></item></channel></rss>