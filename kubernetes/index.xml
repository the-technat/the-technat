<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Kubernetes on ssh technat</title><link>https://technat.ch/kubernetes/</link><description>Recent content in Kubernetes on ssh technat</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://technat.ch/kubernetes/index.xml" rel="self" type="application/rss+xml"/><item><title>argocd</title><link>https://technat.ch/kubernetes/argocd/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/kubernetes/argocd/</guid><description>Chart: https://artifacthub.io/packages/helm/argo/argo-cd
Repo: https://argo-cd.readthedocs.io/en/stable/getting_started/#1-install-argo-c://github.com/argoproj/argo-helm
Install helm upgrade -i argocd argo/argo-cd -n argocd --create-namespace -f argocd-values.yaml Local Users Create Add the following to the argocd-cm ConfigMap:
accounts.dev: login accounts.ci: apiKey accounts.technat: login accounts.admin.enabled: &amp;#34;false&amp;#34; Or the argocd.config key in the helm chart.
Permissions Now edit the argocd-rbac-cm ConfigMap and add the following to map the technat user admin rights.
data: policy.default: role:readonly policy.csv: | g, technat, role:admin p, role:ci, applications, *, */*, allow g, ci, role:ci Or the argocd.</description></item><item><title>cert-manager</title><link>https://technat.ch/kubernetes/cert-manager/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/kubernetes/cert-manager/</guid><description>Installation helm repo add jetstack https://charts.jetstack.io helm repo update helm show values jetstack/cert-manager &amp;gt; cert-manager-values.yaml kubectl create ns cert-manager helm upgrade -i cert-manager -n cert-manager jetstack/cert-manager -f cert-manager-values.yaml Let&amp;rsquo;s Encrypt Issuer kubectl apply -f letsencrypt-staging.yaml kubectl apply -f letsencrypt-production.yaml Resources - https://cert-manager.io/docs/tutorials/acme/ingress/
Files Custom Values: cert-manager-values.yaml
Let&amp;rsquo;s Encrypt Staging Issuer: letsencrypt-staging.yaml
Let&amp;rsquo;s Encrypt Production Issuer: letsencrypt-production.yaml</description></item><item><title>external-dns</title><link>https://technat.ch/kubernetes/external-dns/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/kubernetes/external-dns/</guid><description>Prepare See https://github.com/kubernetes-sigs/external-dns/tree/master/charts/external-dns
Install kubectl create ns external-dns helm upgrade -i external-dns -n external-dns external-dns/external-dns --set env.0.value=&amp;lt;APITOKEN_HERE&amp;gt; -f external-dns-values.yaml Files Custom Values: external-dns-values.yaml</description></item><item><title>gitlab-runners</title><link>https://technat.ch/kubernetes/gitlab-runner/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/kubernetes/gitlab-runner/</guid><description>Chart: https://artifacthub.io/packages/helm/gitlab/gitlab-runner
Preparations helm repo add gitlab http://charts.gitlab.io/ helm show values gitlab/gitlab-runner &amp;gt; gitlab-runner-values.yaml kubectl create ns gitlab-runners Configure Cache Apply the CRD to create the cache:
kubectl apply -f cache-bucket.yaml Get the information from the configmap and fill it into the helm values:
kubectl get configmap gitlab-cache -o yaml For the credentials we have to create a new secret based on the current one that rook-ceph created:
kubectl create secret generic s3access \ --from-literal=accesskey=&amp;#34;&amp;#34; \ --from-literal=secretkey=&amp;#34;&amp;#34; Install helm upgrade -i k8s-at-hetzner-runner -n gitlab-runners gitlab/gitlab-runner -f k8s-at-hetzner-runner-values.</description></item><item><title>heimdall</title><link>https://technat.ch/kubernetes/heimdall/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/kubernetes/heimdall/</guid><description>Chart: https://artifacthub.io/packages/helm/k8s-at-home/heimdall
Installation helm repo add k8s-at-home https://k8s-at-home.com/charts/ helm repo update helm show values k8s-at-home/heimdall &amp;gt; heimdall-values.yaml helm upgrade -i heimdall --create-namespace -n heimdall k8s-at-home/heimdall -f heimdall-values.yaml Files Custom heimdall values: heimdall-values.yaml
Service for Heimdall: heimdall-lb.yaml</description></item><item><title>ingress-nginx</title><link>https://technat.ch/kubernetes/ingress-nginx/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/kubernetes/ingress-nginx/</guid><description>References - https://github.com/kubernetes/ingress-nginx
- https://kubernetes.github.io/ingress-nginx/deploy/#using-helm
Install k create ns ingress-nginx helm upgrade ingress-nginx -i -n ingress-nginx ingress-nginx/ingress-nginx -f helm-ingress-nginx.yaml External Access To have external access add port-forwarding rules in Firewall to forward 80/443 to ingress-nginx
Files Custom Values: helm-ingress-nginx.yaml</description></item><item><title>k8s_kubeadm</title><link>https://technat.ch/kubernetes/k8s_kubeadm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/kubernetes/k8s_kubeadm/</guid><description>This is my current approach on how to setup Kubernetes for labing purposes. I&amp;rsquo;m not a fan of automation when It comes to trying things out, so my setup is completely manual using kubeadm.
Here are some other aspects of my setup that will be part of this guide:
My Cloud Provider of choice is currently Hetzner Public facing K8s - no traffic going over private networks My CNI of choice is currently Cilium with pod to pod encryption using wireguard Prerequisites Before we dive into the details on how to setup, here are some prerequisites to met when you want to follow allong:</description></item><item><title>kubeinvaders</title><link>https://technat.ch/kubernetes/kubeinvaders/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/kubernetes/kubeinvaders/</guid><description>Preparations helm repo add kubeinvaders https://lucky-sideburn.github.io/helm-charts Install helm upgrade -i kubeinvaders -n kubeinvaders --create-namespace kubeinvaders/kubeinvaders -f kubeinvaders-values.yaml Files Custom Values: kubeinvaders-values.yaml</description></item><item><title>lv-extending</title><link>https://technat.ch/kubernetes/lv-extending/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/kubernetes/lv-extending/</guid><description>Containers have their temporare file system on the node under /var/.... This means that K8s worker nodes need to have a big /var if you mount this on a separate partition.
If using LVM and VMs we can manually extend the logical volume behind /var. But for this the volume must be unmounted, so we need to use a live installation.
First drain the node:
k drain node-0x --ignore-daemonsets --delete-empty-dir-data Then we shutdown the node and mount a live-iso.</description></item><item><title>metallb</title><link>https://technat.ch/kubernetes/metallb/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/kubernetes/metallb/</guid><description>Install helm upgrade -i metallb -n metallb-system -f metallb-values.yaml metallb/metallb Files Custom Values: metallb-values.yaml
Layer2 Config: metallb-config.yaml</description></item><item><title>metrics-server</title><link>https://technat.ch/kubernetes/metrics-server/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/kubernetes/metrics-server/</guid><description>See https://github.com/kubernetes-sigs/metrics-server/blob/master/charts/metrics-server/README.md
Install helm upgrade -i metrics-server metrics-server/metrics-server -f metrics-server-values.yaml Files Custom Values: metrics-server-values.yaml</description></item><item><title>rook-ceph</title><link>https://technat.ch/kubernetes/rook-ceph/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://technat.ch/kubernetes/rook-ceph/</guid><description>Maybe you know rook.io. Rook is a storage operator.
Rook can configure Ceph clusters based on CRDS. Ceph provides Block, File and Object storage.
The workers nodes used in this values file have each an empty 50GB disk attached. By default rook will only take disks that are unused.
rook-ceph chart We start by installing the rook-operator which gives us the base to deploy ceph later on:
helm repo add rook-release https://charts.</description></item></channel></rss>